{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-minute ONNX Primer: Caffe2$\\rightarrow$ONNX and back\n",
    "\n",
    "**Author:** [Nathan Inkawhich](https://github.com/inkawhich)\n",
    "\n",
    "This tutorial is a brief look at how to use Caffe2 and [ONNX](http://onnx.ai/about) together. More specifically, we will show how to export a model from Caffe2 to ONNX and how to import a model from ONNX into Caffe2. Hopefully, the motivation is clear but this tutorial shows how to use the very fast and efficient Caffe2 framework with the flexibility enabling ONNX framework. One important fact to keep in mind is that ONNX is designed to enable deployment and *inference* in frameworks other than where the model was trained. Currently, there is no streamlined way to finetune ONNX models. The workflow for this document is as follows:\n",
    "\n",
    "- Run prediction with a Caffe2 model and collect initial prediction\n",
    "- Export the Caffe2 model to ONNX format\n",
    "- Import the saved ONNX model back into Caffe2\n",
    "- Run prediction on imported model and verify results\n",
    "\n",
    "Let's get started with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "import numpy as np\n",
    "import operator\n",
    "from caffe2.proto import caffe2_pb2\n",
    "from caffe2.python import core, workspace, models\n",
    "import onnx\n",
    "import caffe2.python.onnx.frontend # Required for Caffe2->ONNX export\n",
    "import caffe2.python.onnx.backend # Required for ONNX->Caffe2 import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Now we will specify the inputs. The *MODELS_DIR* is where the downloaded Caffe2 models are saved, the *MODEL_NAME* is the name of the model we want to use, and *SIZE* is the size of image the model expects. For more information about downloading a pretrained Caffe2 model, see the [Loading Pretrained Models Tutorial](https://github.com/caffe2/tutorials/blob/master/Loading_Pretrained_Models.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Inputs\n",
    "MODELS_DIR = \"../models\"\n",
    "MODEL_NAME = \"squeezenet\" # e.g. [squeezenet, bvlc_alexnet, bvlc_googlenet, bvlc_reference_caffenet]\n",
    "SIZE = 224\n",
    "\n",
    "# Construct path strings from inputs\n",
    "INIT_NET = \"{}/{}/init_net.pb\".format(MODELS_DIR, MODEL_NAME)\n",
    "PREDICT_NET = \"{}/{}/predict_net.pb\".format(MODELS_DIR, MODEL_NAME)\n",
    "ONNX_MODEL = \"{}/{}/my_model.onnx\".format(MODELS_DIR, MODEL_NAME) # we will create this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Caffe2 Model\n",
    "\n",
    "Before we perform the export we will first load the pretrained init and predict nets, then create a *Predictor*. Next, we will create a random input to get a baseline result for comparision later. Take note of the predicted label and confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  (1, 3, 224, 224)\n",
      "Results Shape:  (1, 1, 1000, 1, 1)\n",
      "Top-1 Prediction: 111 @ 0.12546874582767487\n"
     ]
    }
   ],
   "source": [
    "# Generate random NCHW input to run model\n",
    "#   This is a placeholder for any real image that is processed and\n",
    "#   put in NCHW order.\n",
    "image = np.random.rand(1,3,SIZE,SIZE).astype(np.float32)\n",
    "print(\"Input Shape: \",image.shape)\n",
    "\n",
    "# Prepare the nets\n",
    "predict_net = caffe2_pb2.NetDef()\n",
    "with open(PREDICT_NET, 'rb') as f:\n",
    "    predict_net.ParseFromString(f.read())\n",
    "init_net = caffe2_pb2.NetDef()\n",
    "with open(INIT_NET, 'rb') as f:\n",
    "    init_net.ParseFromString(f.read())\n",
    "\n",
    "# Initialize the predictor from the nets\n",
    "p = workspace.Predictor(init_net, predict_net)\n",
    "\n",
    "#### Run the sample data\n",
    "\n",
    "# Run the net and return prediction\n",
    "results = p.run({'data': image})\n",
    "results = np.asarray(results)\n",
    "print(\"Results Shape: \", results.shape)\n",
    "\n",
    "# Quick way to get the top-1 prediction result\n",
    "curr_pred, curr_conf = max(enumerate(np.squeeze(results)), key=operator.itemgetter(1))\n",
    "print(\"Top-1 Prediction: {} @ {}\".format(curr_pred, curr_conf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caffe2 $\\rightarrow$ ONNX Export\n",
    "\n",
    "Finally, we have reached the interesting stuff. It is not hard to imagine why one may want to export a Caffe2 model to ONNX. Maybe you have a cool idea for an iPhone app and want to use a model trained in Caffe2 with CoreML as part of the app. Or, maybe you have a system built in Tensorflow but want to test out a model from the Caffe2 Model Zoo. ONNX enables this interoperability by allowing models to be imported and exported into different frameworks (for inference!).\n",
    "\n",
    "The code below shows how to **export** a model trained in Caffe2 to ONNX format. Once in ONNX format, the model can be imported into any other compatible framework to be used for *inference*. From the Caffe2 side, we only need the previously loaded *init_net* and *predict_net* *caffe2_pb2.NetDef* objects. \n",
    "\n",
    "There are only a few steps to export once the nets are loaded. First, we must declare (via Python dictionary) the type and shape of inputs and outputs of the model. This information is not explicitly specified in the Caffe2 model architecture but is required by ONNX. Next, we must make sure the model has a name, otherwise the internal model checks in the ONNX converter will fail. Then, all thats left to do is create the ONNX model, check it, and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to provide type and shape of the model inputs\n",
    "data_type = onnx.TensorProto.FLOAT\n",
    "data_shape = (1, 3, 224, 224)\n",
    "value_info = {\n",
    "    'data': (data_type, data_shape)\n",
    "}\n",
    "\n",
    "# Make sure the net has a name. Otherwise, the checker will fail.\n",
    "if predict_net.name == \"\":\n",
    "    predict_net.name = \"ModelNameHere\"\n",
    "\n",
    "# Create the ONNX model\n",
    "onnx_model = caffe2.python.onnx.frontend.caffe2_net_to_onnx_model(\n",
    "    predict_net,\n",
    "    init_net,\n",
    "    value_info,\n",
    ")\n",
    "\n",
    "# Check the ONNX model. Exception will be thrown if there is a problem here.\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Save the ONNX model\n",
    "onnx.save(onnx_model, ONNX_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX $\\rightarrow$ Caffe2 Import\n",
    "\n",
    "Now suppose someone has trained Alexnet2.0 which gets 99.9% top-1 test accuracy on ImageNet ... *gasp* ... in Tensorflow. As a Caffe2 user, all we have to do is convince them to convert the model to ONNX format, then we can import it and use it. Since we are running out of time in this 5-minute primer, here we will only show how to import the model we just exported back into Caffe2. The import happens in a single load command (`onnx.load`), then we can start feeding the model data in just one more command (`run_model`). Also, note that the predictions from this imported model and the original model are the exact same, indicating nothing was lost in the export/import process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape:  (1, 1, 1000, 1, 1)\n",
      "Top-1 Prediction: 111 @ 0.12546874582767487\n"
     ]
    }
   ],
   "source": [
    "# Load the ONNX model\n",
    "model = onnx.load(ONNX_MODEL)\n",
    "\n",
    "# Run the ONNX model with Caffe2\n",
    "outputs = caffe2.python.onnx.backend.run_model(model, [image])\n",
    "print(\"Output Shape: \", np.array(outputs).shape)\n",
    "\n",
    "# Get model prediction\n",
    "curr_pred, curr_conf = max(enumerate(np.squeeze(results)), key=operator.itemgetter(1))\n",
    "print(\"Top-1 Prediction: {} @ {}\".format(curr_pred, curr_conf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully it is clear that the caffe2-onnx interface for both importing and exporting is relatively simple. For more information about ONNX and to see more tutorials on using ONNX with different frameworks see the [ONNX Tutorials](https://github.com/onnx/tutorials). Also, although importing and exporting with Caffe2 is supported, and exporting a model from PyTorch to ONNX is supported, *importing* an ONNX model into PyTorch is *NOT*, but is coming soon!\n",
    "\n",
    "Here are some more cool ONNX resources for the curious reader:\n",
    "\n",
    "- [ONNX Python API Overview](https://github.com/onnx/onnx/blob/master/docs/PythonAPIOverview.md)\n",
    "- [ONNX Model Zoo](https://github.com/onnx/models)\n",
    "- [ONNX Operators](https://github.com/onnx/onnx/blob/master/docs/Operators.md)\n",
    "- [ONNX Tutorials](https://github.com/onnx/tutorials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pc27]",
   "language": "python",
   "name": "conda-env-pc27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
